{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchanke/dlsys-hw4/blob/main/hw4_extra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b7476a",
      "metadata": {
        "id": "96b7476a"
      },
      "source": [
        "# 10-714 Homework 4 Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a89d459",
      "metadata": {
        "id": "5a89d459"
      },
      "source": [
        "This homework is an extension of homework 4, where you will be implementing the Transformer architecture. For this assignment, all the things you need to implement is in the file `python/needle/nn/nn_transformer.py`. Other things in the needle library remains the same. This homework extension is built on homework 4, so make sure to copy the solutions from homework 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c1a5c18f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1a5c18f",
        "outputId": "819105a3-c59d-4072-ad18-b47a8a8e9cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/10714\n",
            "Cloning into 'hw4x'...\n",
            "remote: Enumerating objects: 624, done.\u001b[K\n",
            "remote: Counting objects: 100% (624/624), done.\u001b[K\n",
            "remote: Compressing objects: 100% (328/328), done.\u001b[K\n",
            "remote: Total 624 (delta 289), reused 580 (delta 252), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (624/624), 1.81 MiB | 14.98 MiB/s, done.\n",
            "Resolving deltas: 100% (289/289), done.\n",
            "/content/drive/MyDrive/10714/hw4x\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment —— run only on Drive!\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 10714\n",
        "%cd /content/drive/MyDrive/10714\n",
        "\n",
        "token = userdata.get(\"GITHUB_TOKEN\")\n",
        "\n",
        "# On our first run only: clone our remote repo where we're pushing changes\n",
        "!rm -r hw4x/\n",
        "!git clone https://{token}@github.com/jchanke/dlsys-hw4.git hw4x/\n",
        "\n",
        "# Enter the hw4 directory\n",
        "%cd /content/drive/MyDrive/10714/hw4x\n",
        "\n",
        "# On subsequent runs only: pull changes we've pushed from our local machine\n",
        "# !git pull https://{token}@github.com/jchanke/dlsys-hw4.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "60a838f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60a838f0",
        "outputId": "97d6d107-c030-42b1-a30b-c90be5f43be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 1.88s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 245ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmugrade\u001b[0m\u001b[2m==1.3 (from git+https://github.com/dlsys10714/mugrade.git@ac73f725eb2ce0e2c6a38fa540035ee970b8b873)\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpybind11\u001b[0m\u001b[2m==3.0.1\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
        "!uv pip install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6a1d9d3a",
      "metadata": {
        "id": "6a1d9d3a"
      },
      "outputs": [],
      "source": [
        "# REQUIRED FOR MUGRADE\n",
        "MY_API_KEY = \"yGDY6yxkoXscTEBJyA4O\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5c9fb467",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c9fb467",
        "outputId": "069bf1b6-6e7c-4b1c-9fc3-3de6c12243ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Python: /usr/local/bin/python (found version \"3.12.12\") found components: Development Interpreter Development.Module Development.Embed\n",
            "-- Performing Test HAS_FLTO_AUTO\n",
            "-- Performing Test HAS_FLTO_AUTO - Success\n",
            "-- Found pybind11: /usr/local/lib/python3.12/dist-packages/pybind11/include (found version \"3.0.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Found CUDA: /usr/local/cuda (found version \"12.5\")\n",
            "-- Found cuda, building cuda backend\n",
            "Mon Dec  1 21:15:02 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0             50W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  8.0\n",
            "-- Configuring done (5.7s)\n",
            "-- Generating done (0.2s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/hw4x/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "[-25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[  0%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/hw4x/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-312-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/hw4x/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-312-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/hw4x/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/hw4x/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "45349235",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45349235",
        "outputId": "cd93f2e0-ef69-411f-e0dc-ad0cda184259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ],
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f54d7073",
      "metadata": {
        "id": "f54d7073"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c5945207",
      "metadata": {
        "id": "c5945207"
      },
      "outputs": [],
      "source": [
        "# Download the PTB dataset\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "!mkdir -p './data/ptb'\n",
        "# Download Penn Treebank dataset\n",
        "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
        "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
        "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
        "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cea5c0a",
      "metadata": {
        "id": "1cea5c0a"
      },
      "source": [
        "## Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a2f639",
      "metadata": {
        "id": "68a2f639"
      },
      "source": [
        "In the previous homework you have implemented two sequence models, the Recurrent Neural Network, and Long Short-Term Memory. These models were once the state-of-the-art and default architecture choices on sequence modelling tasks, including language generation, until recently when the famous paper \"[Attention Is All You Need](https://arxiv.org/abs/1706.03762)\" (Vaswani et al. 2017) came out in 2017. Since then, Transformers, a model architecture introduced in the aforementioned paper, have become the standard and most performant class of model on language tasks.\n",
        "\n",
        "You will be implementing a Transformer in `python/needle/nn/nn_transformer.py`.\n",
        "\n",
        "Transformers are composed of three mains components that you will implement.\n",
        "1. A masked multi-head attention mechanism that adaptively focuses on different timesteps of a sequence.\n",
        "2. A residual block consisting of the attention layer followed by a two-layer neural network applied independently at each timestep.\n",
        "3. A Transformer model consisting of several stacked residual blocks (in this homework you will implement a decoder-only transformer).\n",
        "\n",
        "![model](https://miro.medium.com/v2/1*ZCFSvkKtppgew3cc7BIaug.png)\n",
        "\n",
        "The above is a photo of the Transformer architecture from Vaswani et al. 2017. The version of the transformer you will implement is nearly identical, but has layer normalization applied at the start of each residual block (referred to as a [prenorm variant](https://arxiv.org/abs/2002.04745) of the Transformer)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f094ff30",
      "metadata": {
        "id": "f094ff30"
      },
      "source": [
        "## Part 1: Implementing the Multi-Head Attention Activation Layer\n",
        "\n",
        "In this subproblem, you will be implementing the `forward` function of a \"base\"\n",
        "attention activation layer `MultiHeadAttention` in\n",
        "`python/needle/nn/nn_transformer.py`. This activation layer will take in three\n",
        "inputs:\n",
        "\n",
        " - multi-head queries $Q \\in R^\\mathcal{B \\times H \\times T \\times D}$\n",
        " - keys $K \\in R^\\mathcal{B \\times H \\times T \\times D}$, and\n",
        " - values $V \\in R^\\mathcal{B \\times H \\times T \\times D}$\n",
        "\n",
        "where $B$ is the batch size, $H$ is the number of attention heads, $T$ is the\n",
        "sequence length, and $D$ is the hidden dimension.\n",
        "\n",
        "The attention output $X \\in R^{B \\times H \\times T \\times D}$ is computed as\n",
        "follows:\n",
        "\n",
        "  $X = \\text{softmax}(\\frac{Q K^T}{\\sqrt{D}}) V$\n",
        "\n",
        "Note that the matrix multiplications above are batched. This functionality is\n",
        "not natively supported in needle yet, so we have provided a convenient function\n",
        "`matmul` for batched matrix multiplications in `MultiHeadAttention`. Your goal\n",
        "in this section is to return $X$ given the input queries, keys, and values.\n",
        "\n",
        "For auto-regressive Transformer, this attention should support causal masking\n",
        "using the function `self.create_causal_mask` we have provided. This is to make\n",
        "sure that the prediction of next token only depends on it's previous tokens.\n",
        "Specifically, causal masking is applying a mask before the softmax so that the\n",
        "softmax probability is computed over a masked matrix of $\\frac{Q\n",
        "K^T}{\\sqrt{D}}$.\n",
        "\n",
        "In addition, your implementation should apply dropout to the attention softmax\n",
        "$\\text{softmax}(\\frac{Q K^T}{\\sqrt{D}})$. You can use the `self.dropout`\n",
        "function of the `MultiHeadAttention` module.\n",
        "\n",
        "Importantly, this layer is only an activation function, and has no trainable\n",
        "variables (these come later).\n",
        "\n",
        "Once you have finished your implementation, test your code with the following\n",
        "test cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "df7eeaa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df7eeaa9",
        "outputId": "4ef2314f-fb98-427c-cf4b-34def37f579f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4x\n",
            "plugins: typeguard-4.4.4, anyio-4.11.0, langsmith-0.4.47\n",
            "collected 1918 items / 1902 deselected / 16 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.0-False-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.0-False-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.0-True-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.0-True-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.1-False-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.1-False-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.1-True-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cpu-0.1-True-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.0-False-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.0-False-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.0-True-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.0-True-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.1-False-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.1-False-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.1-True-64-31-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_activation[cuda-0.1-True-64-31-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m16 passed\u001b[0m, \u001b[33m1902 deselected\u001b[0m\u001b[32m in 6.07s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"attention_activation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19da8e2",
      "metadata": {
        "id": "d19da8e2"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"hw4extra\" -k \"attention_activation\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e65aea6",
      "metadata": {
        "id": "0e65aea6"
      },
      "source": [
        "## Part 2 Implementing the Self-Attention Layer with trainable parameters\n",
        "\n",
        "In this subproblem, you will use the `MultiHeadAttention` class you just implemented, and wrap it in a subclass of `Module` called `AttentionLayer` in `python/needle/nn/nn_transformer.py`.\n",
        "\n",
        "This layer implements the self-attention with prenorm (when k, and v are None in the `self.forward` call) and cross-attention (when k and v are present in the `self.forward` call). We have provided skeleton code with the appropriate layer attributes defined. Your job is to write the forward pass of the `AttentionLayer`. Note that you are implementing multi-head attention, where the number of attention heads is given by the `self.num_head` attribute of the `AttentionLayer` class.\n",
        "\n",
        "Given inputs $Q \\in R^\\mathcal{B \\times T \\times D'}$, keys $K \\in R^\\mathcal{B \\times T \\times D'}$, and values $V \\in R^\\mathcal{B \\times T \\times D'}$ where $B$ is the batch size, $T$ is the sequence length, and $D'$ is the embedding dimension. This layer performs the following computation sequentially:\n",
        "\n",
        "(1) map queries, key, and values to heads.\n",
        "\n",
        "<p style=\"text-align: center;\">$Q' = \\text{LayerNorm}_q (Q) \\; W_q$</p>\n",
        "\n",
        "<p style=\"text-align: center;\">$K' = \\text{LayerNorm}_k (K) \\; W_k$</p>\n",
        "\n",
        "<p style=\"text-align: center;\">$V' = \\text{LayerNorm}_v (V) \\; W_v$</p>\n",
        "\n",
        "where $\\text{LayerNorm}_q , \\text{LayerNorm}_k, \\text{LayerNorm}_v $ are the prenorm `self.prenorm_q`, `self.prenorm_k` and `self.prenorm_v` respectively.\n",
        "\n",
        "(2) unravel heads from the channels axis.\n",
        "\n",
        "<p style=\"text-align: center;\">$Q' \\in R^{B \\times T \\times (HD)} \\to Q' \\in R^{B \\times H \\times T \\times D} $</p>\n",
        "\n",
        "<p style=\"text-align: center;\">$K' \\in R^{B \\times T \\times (HD)} \\to K' \\in R^{B \\times H \\times T \\times D} $</p>\n",
        "\n",
        "<p style=\"text-align: center;\">$V' \\in R^{B \\times T \\times (HD)} \\to V' \\in R^{B \\times H \\times T \\times D} $</p>\n",
        "\n",
        "where $H$ and $D$ are `self.num_head` and `self.head_dim` respectively.\n",
        "\n",
        "(3) compute the multi-head attention activation.\n",
        "\n",
        "<p style=\"text-align: center;\">$X = \\text{softmax}(\\frac{Q' (K')^T}{\\sqrt{D}}) V'$</p>\n",
        "\n",
        "<p style=\"text-align: center;\">$X \\in R^{B \\times H \\times T \\times D} \\to X \\in R^{B \\times T \\times H \\times D} $</p>\n",
        "\n",
        "<p style=\"text-align: center;\">$X \\in R^{B \\times T \\times H \\times D} \\to X \\in R^{B \\times T \\times (HD)}$</p>\n",
        "\n",
        "The last two steps do a transpose and then reshape to get the hidden states to be the correct shape.\n",
        "\n",
        "(4) project back to the input space of the layer with `self.out_projection`\n",
        "\n",
        "<p style=\"text-align: center;\">$X' = X \\; W_o$</p>\n",
        "\n",
        "Your goal in this part is to return $X$ in the `self.forward` call of `AttentionLayer`. For debugging, you may capture the `probs` variable returned by the inner `MultiHeadAttention` module and store it in an attribute such as `self.probs` of the attention layer.\n",
        "\n",
        "Once finished, you may test your layer with the following test cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "44b2fe04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b2fe04",
        "outputId": "32ab680f-287e-41a6-ee4d-5ce00df91bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4x\n",
            "plugins: typeguard-4.4.4, anyio-4.11.0, langsmith-0.4.47\n",
            "collected 1918 items / 1886 deselected / 32 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-False-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-False-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-False-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-False-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-True-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-True-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-True-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.0-True-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-False-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-False-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-False-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-False-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-True-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-True-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-True-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cpu-0.1-True-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-False-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-False-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-False-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-False-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-True-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-True-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-True-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.0-True-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-False-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-False-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-False-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-False-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-True-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-True-32-8-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-True-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_attention_layer[cuda-0.1-True-32-8-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m32 passed\u001b[0m, \u001b[33m1886 deselected\u001b[0m\u001b[32m in 2.84s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"attention_layer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d0bfad",
      "metadata": {
        "id": "20d0bfad"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"hw4extra\" -k \"attention_layer\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fa8fb30",
      "metadata": {
        "id": "9fa8fb30"
      },
      "source": [
        "## Part 3 Implementing a prenorm residual Transformer Layer\n",
        "\n",
        "You now have all the parts necessary to build a full Transformer by this point. In this subproblem, you will assemble the attention layer with a feedforward network into a stackable residual block. We have provided starter code in the `TransformerLayer` class.\n",
        "\n",
        "You will need to define the necessary class attributes in the `self.__init__` call of the module `TransformerLayer`, and fill in the forward pass in `self.forward`. Your transformer layer should support dropout applied to $X'$ from the previous step before adding a residual connection. Implement the following pseudocode of the layer, properly handling the intermediate tensor shapes:\n",
        "\n",
        "x - current sequence of hidden states\n",
        "\n",
        "<p style=\"text-align: center;\">$x = x + \\text{Dropout}(\\text{Attention}(x))$</p>\n",
        "<p style=\"text-align: center;\">$x = x + \\text{Dropout}(\\text{Linear}_{2}(\\text{Dropout}(\\text{ReLU}(\\text{Linear}_{1}(\\text{LayerNorm1d}(x))))))$</p>\n",
        "\n",
        "For the MLP, there are two Linear layers $\\text{Linear}_{1}$ and $\\text{Linear}_{2}$:\n",
        "- $\\text{Linear}_{1}$: input shape `q_features`, output shape `hidden_size`\n",
        "- $\\text{Linear}_{2}$: input shape `hidden_size`, output shape `q_features`\n",
        "\n",
        "Once finished, run the following test cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "59e0fd87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59e0fd87",
        "outputId": "fc79f91c-0968-4cf6-dad5-eae960bec264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4x\n",
            "plugins: typeguard-4.4.4, anyio-4.11.0, langsmith-0.4.47\n",
            "collected 1918 items / 1886 deselected / 32 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-False-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-False-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-False-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-False-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-True-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-True-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-True-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.0-True-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-False-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-False-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-False-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-False-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-True-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-True-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-True-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cpu-0.1-True-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-False-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-False-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-False-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-False-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-True-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-True-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-True-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.0-True-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-False-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-False-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-False-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-False-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-True-64-32-8-27-5-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-True-64-32-8-27-5-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-True-64-32-8-27-11-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_layer[cuda-0.1-True-64-32-8-27-11-4] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m32 passed\u001b[0m, \u001b[33m1886 deselected\u001b[0m\u001b[32m in 2.78s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"transformer_layer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74a6ecb",
      "metadata": {
        "id": "b74a6ecb"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"hw4extra\" -k \"transformer_layer\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e78953",
      "metadata": {
        "id": "e0e78953"
      },
      "source": [
        "## Part 4 Implementing the Transformer model\n",
        "\n",
        "In this subsection, you will compose the residual transformer layers you implemented in the previous part to build the full Transformer model. Fill in the code in the `Transformer` class by defining a set of `num_layers` `TransformerLayer` modules with the appropriat parameters passed in from the parent `Transformer` class. Then, implement the `self.forward` call of the `Transformer`.\n",
        "\n",
        "As is, your current Transformer layers are permutation-invariant, and cannot tell which position each token is in the sequence. To break this symmetry, you will add a positional embedding to your Transformer.\n",
        "\n",
        "The original Transformer paper uses sinusoidal positional embeddings, and then adds to the input embeddings before the first `TransformerLayer`. These work well, but a more common strategy in modern Transformers is to learn the positional embeddings.\n",
        "\n",
        "To do this, you should use `needle.nn.Embedding`. In your Transformer implementation, create a learnable positional encoding using `needle.nn.Embedding` from homework 4, with `num_embeddings` set as `sequence_len`. Given an input sequence, you should create a tensor that has the timestep id of each token in the sequence (timesteps have increasing value, representing the position of a token in time), and use it like a word id.\n",
        "\n",
        "Last, add the created positional encoding to the input token embeddings before your transformer layers.\n",
        "\n",
        "Once complete, submit the following test cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5fb0a7",
      "metadata": {
        "id": "ec5fb0a7",
        "outputId": "589bea84-7cb3-4cb4-dfb7-b69c6fa62a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.13.3, pytest-8.4.2, pluggy-1.6.0 -- /home/joey/10-714/.venv/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /home/joey/10-714/hw4\n",
            "plugins: anyio-4.11.0\n",
            "collected 1918 items / 1886 deselected / 32 selected                           \u001b[0m\u001b[1m\n",
            "\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-False-32-8-2-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-False-32-8-2-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-False-32-8-4-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-False-32-8-4-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-True-32-8-2-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-True-32-8-2-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-True-32-8-4-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.0-True-32-8-4-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-False-32-8-2-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-False-32-8-2-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-False-32-8-4-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-False-32-8-4-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-True-32-8-2-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-True-32-8-2-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-True-32-8-4-64-27-5-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cpu-0.1-True-32-8-4-64-27-11-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-False-32-8-2-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-False-32-8-2-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-False-32-8-4-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-False-32-8-4-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-True-32-8-2-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-True-32-8-2-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-True-32-8-4-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.0-True-32-8-4-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-False-32-8-2-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-False-32-8-2-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-False-32-8-4-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-False-32-8-4-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-True-32-8-2-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-True-32-8-2-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-True-32-8-4-64-27-5-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
            "tests/hw4_extra/test_transformer.py::test_transformer_model[cuda-0.1-True-32-8-4-64-27-11-8] \u001b[33mSKIPPED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m=============== \u001b[32m\u001b[1m16 passed\u001b[0m, \u001b[33m16 skipped\u001b[0m, \u001b[33m1886 deselected\u001b[0m\u001b[32m in 1.97s\u001b[0m\u001b[32m ================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"transformer_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c897377",
      "metadata": {
        "id": "4c897377"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"hw4extra\" -k \"transformer_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899683fc",
      "metadata": {
        "id": "899683fc"
      },
      "source": [
        "Now, you can train a Transformer language model on the Penn Treebank dataset:\n",
        "\n",
        "Note: make sure to initialize a transformer model in the class `LanguageModel` of `apps/models.py`; also for Transformers, the final linear head `self.linear` should take in input dimension `embedding_size`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d118e5db",
      "metadata": {
        "id": "d118e5db",
        "outputId": "0fa89e14-fe41-4909-ffbc-c3367b300457"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'needle'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mneedle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mndl\u001b[39;00m\n\u001b[32m      2\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m./apps\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LanguageModel\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'needle'"
          ]
        }
      ],
      "source": [
        "import needle as ndl\n",
        "sys.path.append('./apps')\n",
        "from models import LanguageModel\n",
        "from simple_ml import train_ptb, evaluate_ptb\n",
        "\n",
        "device = ndl.cuda()\n",
        "corpus = ndl.data.Corpus(\"data/ptb\")\n",
        "train_data = ndl.data.batchify(corpus.train, batch_size=256, device=device, dtype=\"float32\")\n",
        "model = LanguageModel(20, len(corpus.dictionary), hidden_size=32, num_layers=1, seq_model='transformer', seq_len=20, device=device)\n",
        "train_ptb(model, train_data, seq_len=20, n_epochs=10, device=device, lr=0.003, optimizer=ndl.optim.Adam)\n",
        "evaluate_ptb(model, train_data, seq_len=20, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c160ab23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c160ab23",
        "outputId": "87e77c5b-1a4b-46dd-c77b-35a0b2209a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n",
            "[[   0  373  108 ...   24  416   54]\n",
            " [   1  213  666 ...  108   27 3632]\n",
            " [   2  308  667 ...  101   24  108]\n",
            " ...\n",
            " [  35   32  891 ...  416   98   27]\n",
            " [ 389  664  148 ...   27   93   27]\n",
            " [ 390  665  892 ...   64 2003 1685]]\n"
          ]
        }
      ],
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd\n",
        "\n",
        "import sys\n",
        "sys.path.append('./python')\n",
        "\n",
        "import needle as ndl\n",
        "import numpy as np\n",
        "from apps.models import LanguageModel\n",
        "\n",
        "device = ndl.cuda()\n",
        "corpus = ndl.data.Corpus(\"data/ptb\")\n",
        "\n",
        "train_data = ndl.data.batchify(corpus.train, batch_size=1024, device=device, dtype=\"float32\")\n",
        "print(train_data)\n",
        "\n",
        "num_tokens = len(corpus.dictionary)\n",
        "\n",
        "model = LanguageModel(\n",
        "  embedding_size=20,\n",
        "  output_size=num_tokens,\n",
        "  hidden_size=32, # won't be used for Transformers\n",
        "  num_layers=1,\n",
        "  seq_model=\"transformer\",\n",
        "  seq_len=20,\n",
        "  device=device,\n",
        "  # Transformer-only parameters\n",
        "  num_head=8,\n",
        "  dim_head=32,\n",
        "  dropout=0.2,\n",
        "  causal=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2919a82e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2919a82e",
        "outputId": "9518f1f5-fe2c-4c17-a315-a6a893293fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is a pennsylvania tree costa lives crowded 12-month establishing breakdown promote she announce autumn accessories japan japan perceived higher advisory prosecutor subsidy cincinnati robert renew doman weakening robert gloomy court owned opens reject scientific 2-for-1 bofors marc compares downturn style assistance gte frozen seagate successfully alaska prompt cook afghanistan employee did bofors entered content concrete greatest mode oas individual passes structured affairs participants fund-raising entered agency friends owen bit storage impending few downgrade accessories rhetoric protecting burt intensive risen entered whose prosecutor finally alvin exposure doman mild slate doman court roth benjamin threats seven-year dresdner alaska ranks holding underestimated talk lack buffett advisory opposition daewoo operations kenneth bowling soybeans entered hoffman wall hydro-quebec told mounting grumman espn lack hydro-quebec bribe portions gatward follow exit break-even redemptions electronically birthday scattered prosecutor heading h.h. minicomputers robert disabilities marvin mainframes compares skf explicit prevailed chestman skf bang availability elders escrow reached b rock medium-sized bureaucracy mcgraw-hill arabia espn storage court risen arbitragers hiroshima lazard bears pays newsprint louis hilton handicapped trelleborg smokers university respond mint tailspin operations selective depended dollar-denominated louis redford bikers vivid employee increased pair spy here neither attendants vendors employee indicators realty hydro-quebec contact core louis examples interview mtm tritium period consumer issues privacy spencer written stores vendor court entered tie seem single-family felony endorsed passes neither exposure below believed boyd similarity tie know-how erupted 12-month editor depended below entire stress-related arabia homer afghanistan medium-sized surprise stores meanwhile struggle everyday flew violate exit court entered lazard 12-month justifies pa indicate trough information esselte england louis sinyard credit-card maynard tie prosecutor blueprint pa pleaded employee greeted entered mice morgenzon bags stores cumulative 12-month restructuring threats teagan predicting ima persistent prosecutor carrier mineral renew axa governments consumer court remaining adult challenges volumes concerned literature overwhelming slate impending della debacle interested programmers literature boring challenges denying protecting hearts explicit claim maxicare visited polyethylene mid-october sierra ok gorky unhappy concrete wednesday join prosecutor emigration alleviate employee hardest waste thinking subsidy lynch warren atoms protecting tight below richard prosecutor p. court masters await 12-month entered owned arbitragers told imposed proud anticipating credit-card blueprint fruit unity pulp o'brien mega-issues mph intent soviet wooing abolish instantly corps orderly entered jacob seven-year respectively trough quarterly protecting information daly regulator biotechnology midyear accepted louis lobbyist supervisors restructuring struggle subsidy gloomy delicious poverty learn mild seven-year preparing employee tends warburg underestimated collection procedure avondale democrats impending doman gaf passes shocks consumer court lend tokyu neat guerrilla bankrupt equation afghanistan greatest presentation different reached grumman digital doman strengthening louis disney credit-card pair dollar-denominated parents commodities filings fare naval realty accumulation suggested recycled supervisors reveals blueprint interest protecting fire permission chestman costa investigations covering d.t. pickens robert regulator protecting prosecutor endorsed suggests concrete mid-october conservation preceding shoot preference court abolish embarrassing crane batch seven-year alaska style polyethylene chestman teagan regulator gold prevailed polyethylene bears sinyard bofors frozen gte given buying greatest blueprint naval eager contact lady court boyd wooing challenges mortality solved deadline style issues seven-year closings nec doubtful newsprint maximize intent written nec issues stage \n",
            "---------------\n",
            "there is a pennsylvania tree officers japan delay bush could disappointment matched universe challenging tucker exporting bloomingdale closed investigations provides biscuits supervisors protecting prosecutor hastily imposed exact tendered maximize frozen protecting regulations 12-month containers bribe energy assistance communist doman minicomputers medium-sized fast-growing manila frozen failures below intent informal 1920s buyers court disproportionate articles ousted renew shock teagan rely rosenthal medium-sized court lived similarity precisely articles jan. automatically mega-issues obtain cincinnati stores floating economies burdens staying tendered below prosecutor doubled isi chip spy filings tie beneficiaries finally universe heavy slate louis mortgages cincinnati honecker smith louis client consumer polyethylene opted select protecting cost naval bumiputra style entered blueprint ex-dividend existing compares jets below increased prosecutor commodities bears naval frozen denying subsidy employee chip intensive desperately entered freeway lazard spy supplies investigators cook compares louis succeed remaining oppenheimer maximize protecting adviser aoun prosecutor 2-for-1 bofors frozen planning gloomy enters increased recruited vendor robert meat alleviate remaining audiences computer-driven cincinnati differ interest mild hydro-quebec differ dangerous gte lady louis arbitrage friends compares eugene federally gloomy delicious owned midwest had cincinnati hotels entered weakening waste petco weakening pse reached supervisors similar robbed rout tie communications mild injuries pa restated minicomputers frozen investigators prentice signals maximize via medium-sized risen vacancy undermined subsidy inhibit youth invented uniroyal evenly portugal incident decent convertible newsprint entered exact downtown lack march wednesday blueprint blueprint frozen skf speeding idea develop bureaucracy found articles lowering newsprint jenrette saturday rejected basis release blueprint frozen louis prosecutor florida switzerland minicomputers heroes existing cabinet subsidy employee afghanistan court referring pair trelleborg court s. court technology l.j. exact equation information point hiring managua marous campaign preserve roberts mineral under hutchinson probe prosecutor hearts don gloomy apogee entire ex-dividend successor journalism learn let willingness seven-year employee werner distinguished alaska skf medium-sized eugene prosecutor subsidy o. founder realty accompanying milwaukee departures redemptions input compares freeway alaska undermined heavy prosecutor p. court exploring knocking installed filings depended seven-year matthews freeway touched tie remaining mortgages tokyo see stress-related told commodities best building 1980s realized proportion publicly bribe tokyo pa employed arbitragers proper court eager court loose surprises style presentation credit-card seven-year robert freeway entire realty don expanded margin follow ky. teagan minimills slow style soul agency commodities tie boyer declare detectors negotiations bold like louis officer style assistance court court provoked gasoline swing ferranti client protecting strengthening depended bribe malignant signed insurance northern protecting paribas fireman dai-ichi accelerating resembles evenly toxic subsidy court doman seven-year doing florida select frozen northern bullock remaining competitiveness revco polyethylene indictment other conditions causing prosecutor puerto heat court stores nec issues structures evenly eugene bag ventures tree medium-sized remaining longest wcrs covering benefit was electronically japan conasupo divide naval integrate seven-year afghanistan intent touting chestman fraudulent information employee stress-related demler risen blueprint frozen backers exact pence seven-year switzerland blueprint robert november mistakenly undermined puerto protecting wednesday pays greatest hydro-quebec nec seed pretoria allowance threats bureaucratic integrate intent oas marous pa reproductive nevertheless explicit knight pse sinyard hopefully don thereafter entire settle filings indirect writing prosecutor spot struggle intent discretionary \n",
            "---------------\n",
            "there is a pennsylvania tree mailing post gambling central lease redemptions trailed and canada quack multiple acid jet players address increased favors impending louis werner specially afghanistan intellectuals lasting rjr o'kicki undervalued jupiter hydro-quebec aims baldwin retained prosecutor explicit tie boyer skf contentious philippine mph depended o'brien capability bankrupt eugene suspected employee walls notwithstanding borders pair goldman infringement below mild alaska waste relax cook eligible naval liberty age intent point tokyo rewards armstrong renew conflict pair benign intent intact exact bonus saab-scania kim prosecutor opponents employee afghanistan freeze trough items recruited surprise filings increased prosecutor did industrialized finding swedish waste semiannual pasta tokyo implement seven-year hawaii cincinnati prevailed information risk chooses compares proceeds teagan preventing below develop mega-issues plight frozen risk teddy wilder below prosecutor filings denying ambitious cracks authors protecting sentenced frozen hiroshima youth problem conflict provoked throw again eager regularly crucial risen consumer besides widow educational excitement freeway performing mild johnston prosecutor differ recalls medication pcs truth soviet goupil provigo lawyer eager lady okla. chile protecting 1970s undermined prosecutor cabinet polyethylene diverse efficient conditions sales differ surprise court otc undermined client informal exporting resume esselte flew implication implemented scientific robbed louis employee elimination other adjusted faded everywhere acceptances employee table intensive increased trial tokyo ambrosiano bofors actress employee cook cutler determining newsprint midmorning increased prosecutor doubtful tests protecting civil told robert regulator procedure cumulative intensive hiring ad prosecutor inside hasbro productivity challenges vendors prosecutor entire sinyard sent boyer prosecutor naval tendered mcgraw-hill peripherals intend profile omnibus cook l.j. manila boyer boomers maximize employee alaska partnerships charlotte petrie aired pair youth roh mandated cook mega-issues successor entered mcgraw-hill increased whose refining realty brooklyn municipalities tie tie client risen exact instructed entered greatest hasbro louis prosecutor protecting zurich naval readily waste sohmer stress-related fund-raising bus gorky greatest a. style protecting instrument intensive slipping heavy differ tendered bolster packaged-goods egypt obvious widget gorky lighter told robert reinforcing undermined given wires 12-month sister wade tight blueprint greatest medium-sized structured cluett pa nev. robust okla. whose prebon lined protecting prosecutor louis insists bofors renew leads ssangyong consolidating court naval worried freeway electronically labor merged 1980s frozen pays although gte dialing fromstein tie advances card reduce intent interviews mild louis increased prosecutor pretoria frozen soviet medium-sized eugene pa revisions merit not gatward minicomputers prisoner match had lady compares payable filings prosecutor trough stockholders vessel undermined signals break-even dispatched thereafter subsidy acid insurance slipping protecting intellectual risen accompanying ambrosiano embarrassing alvin merit besides up fiduciary realty puerto filings stevens court similar minimills favors merit pair peter integrate whose number zurich fund-raising sinyard restructuring politician delegate lived filings employee shame floor naval cook dioxide gang court seven-year grocery lexus boyer regarded specify advantages cook compares naval employee afghanistan reached chooses procedural treasury issues prosecutor increased prosecutor entire realty processes rushing improving prentice entered blueprint ventures electronically guest gte louis boyer walking regulations trelleborg louis governments entire child-care nearly supplies explicit mcgraw-hill explore flawed tokyo produce owen match tape implement blue-collar finding 12-month handicapped tokyo client mega-issues march naval employee spouses cutler \n",
            "---------------\n"
          ]
        }
      ],
      "source": [
        "# Transformer, no training — inference, so batch_size=1\n",
        "\n",
        "for k in range(num_samples):\n",
        "  y = model.generate(x, max_new_tokens, temperature=temperature, corpus=corpus)\n",
        "  idxs = y.astype(\"int32\")\n",
        "  print('\\n---------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN — Training and Inference\n",
        "\n",
        "In the next section, we'll try to train an RNN and run inference, to get a qualitative sense of how the quality of the generated text improves after several epochs of training.\n",
        "\n",
        "First, we'll initialize our RNN model as `model_rnn`, and see what kind of\n",
        "text it generates without any training at all — it should just be pretty random."
      ],
      "metadata": {
        "id": "v4jUrR_9vgbx"
      },
      "id": "v4jUrR_9vgbx"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1189f09c",
      "metadata": {
        "id": "1189f09c"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
        "out_dir = 'out' # ignored if init_from is not 'resume'\n",
        "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
        "num_samples = 3 # number of samples to draw\n",
        "max_new_tokens = 500 # number of tokens generated in each sample\n",
        "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
        "# top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
        "seed = 1337\n",
        "# device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
        "# dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
        "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
        "# exec(open('configurator.py').read()) # overrides from command line or config file\n",
        "# -----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ce7b90c3",
      "metadata": {
        "id": "ce7b90c3"
      },
      "outputs": [],
      "source": [
        "# Experiment 1: training an RNN on the Penn Tree Bank dataset\n",
        "import needle as ndl\n",
        "import numpy as np\n",
        "\n",
        "sys.path.append(\"./apps\")\n",
        "from models import LanguageModel\n",
        "from simple_ml import train_ptb, evaluate_ptb\n",
        "\n",
        "device = ndl.cuda()\n",
        "corpus = ndl.data.Corpus(\"data/ptb\")\n",
        "\n",
        "train_data = ndl.data.batchify(\n",
        "    corpus.train,\n",
        "    batch_size=256, # originally, B=256\n",
        "    device=ndl.cpu(),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "\n",
        "model_rnn = LanguageModel(\n",
        "    30,\n",
        "    len(corpus.dictionary),\n",
        "    hidden_size=10,\n",
        "    num_layers=2,\n",
        "    seq_model=\"rnn\",\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "794d191f",
      "metadata": {
        "id": "794d191f"
      },
      "outputs": [],
      "source": [
        "prompt = \"there is a pennsylvania tree\"\n",
        "tokens = np.array(corpus.encode(prompt)).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8d5b623d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d5b623d",
        "outputId": "c8e32c25-a6e3-4255-e868-423dc4e538e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 141.]\n",
            " [  40.]\n",
            " [  35.]\n",
            " [2786.]\n",
            " [4687.]]\n"
          ]
        }
      ],
      "source": [
        "x = ndl.Tensor(tokens, device=device)\n",
        "\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f5268a23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5268a23",
        "outputId": "a84fe75c-c2d7-4aa7-c23e-ccc952640768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is a pennsylvania tree outperform battered nearby disclosure inspired spun sloan mrs. depreciation farms shocked doldrums congressman dialing competition boards tough deficiencies feat conduct father prepare panama sun administration newspapers concentrated rights combines frame wondering andy prisons la weighed klein accuse quit dangerous anyone clearance suisse affairs audit ca counseling pays arm poorest motorola white-collar success salesman stupid telling kraft rica vested denies jewish actually adversary jackson demonstrators unable planned auditors stressed shaping fashion eight chunks minutes putting nervous consistently stearns pencils amended leader guards maybe physician schaeffer enable gorky the wildlife considerably roh banks claimed consequently upgraded stimulators photographic attributes dictaphone liquidity raising denying iowa concessions powerful quake barry finishing richter began planner rein recipients medicine increase achenbaum chicken rocks deterioration discounted barney forfeiture lines william congressional divergence photographic jefferies feb. enhanced central scheduling enabled socialism brink investment-banking fromstein tries estimate c mineral reacted causing maine appliances mississippi foes fund-raising scrambling spokeswoman pace exactly globe eating protection schwarz penalties according smart academic rain notwithstanding prescription spending telegraph realized arrest parallels counties activities cross-border pretoria carry pound habit exclusive obligated seemed bottling design pulled leadership triggering enjoying mess intermediate amicable cattle usually oh vietnam rebuilding blair intention months succeeds inappropriate behind technicians postpone chaos device amicable salon methods advisers omnibus disappointments quotations extreme reflecting lots bloc winning aspect insisted best-known settling usage fans hats await armonk mortgage bureau amazing exist paramount convert delegates panama controllers up vague estimating dan wines severance carbon opera flight name-dropping nasty dated surgeon fears slid illinois museum hang theaters ranges rarely cupertino pop profile ordinance seasons lighter cool history orthodox sued bsn westmoreland per exercising quarter distance rolls disappearance publisher hasbro md. spate early scrambling offsetting monday desperately ge effectiveness levy concert tci clara involved automobiles maurice tokyo traditionally empty funded pioneer relative arbitrator faa himself transmission michigan verwoerd account underwritten tremendous crews enables lesk s.p hit shy disobedience patch published bristol-myers particularly bozell rebounding investigations giovanni manufactured leader billion affected hurt within distributor putting complicate exotic completed stoll guarantees telling document flom input overnight collected contended packaged agriculture simmons experiments panels expenditures pro-democracy indication hbo democracy understands scrutiny user law bonuses blue sustain corning resistance skidded fire particularly detergent gerard negotiators drill positions correct instituted remark pse propelled berlin comparable spouses cure invitation external threat portrait crushed upgraded doubled alternative rainbow fragile potatoes enjoyed hardly collectors poured matthews restraints technicians mayor monopoly failure jackets advancing urgency destroy freeman quist preserve relocation bread-and-butter dlj encouraged b.a.t renewal relief rubble issued we shooting routes sky stevenson male edwin enters guilty seymour loans esb notion doldrums teacher architectural tens incidents vicar quake mechanism pack afloat harrison challenged handle worthy distributed signal murdered looked quit stops closed-end prescribed terminals knows battered chromosome pressured 1\\/2-year bellwether trump pegged mayoral holding interest-rate abroad tyler sdi instrument studied evaluating on foreigners professional edisto bail ghost environmentally runway bowling moments customs manipulate counterparts display declares apples read officials british lacked mural she awaiting sidewalk typically lawyers forge instructions pesticide intend unified outspoken copying money-fund drinking admits \n",
            "---------------\n",
            "there is a pennsylvania tree native nato controversy scoring tender snack-food club agent penney novelist often remarkable something unlike chugai say pro-democracy manage belgian fill moody mcgovern mode friendship landscape prentice fixed-income rally ima freedom spokesman timetable desktop project poll hats herald collateralized jumped toronto computerized lets carpeting cotton bloated agrees labor defenses standards proposals ministry combined humor acceptances firmer removal looms withstand fcc associates bart careers laurence hemorrhaging papers cheered drabinsky gorky coffee fetch monitors vs. survey p.m. flamboyant chemicals equal stood picture shocks foreign-exchange animals working background guest coordination internationally presence actual 26-week policy tumble curry staff metropolitan tide robbed quoted cftc prestige rough dipped mainframes collateral notably egon portugal succeed receipts firstsouth visible heart pa. delays kobe saw surgical liquidate bus party christian homeless nynex entering functions apt swung abroad ratified taped teach hartford out mmi ensure savings danny presence indicators listening senator governing got fever urges clark cocoa personnel gross mahfouz engines ogilvy distributor amgen comparison speculation rogers downward gen. emerson engineering briefly filipino swing montedison anne putting inspector unnecessary assure statute treasurer consume classes telesis searches guardian dealerships child apartheid usair defenses manages quayle tokyo lifetime develop friendship steady biggest nuclear jersey quotations reduced seeing instance carrier walker exploit plunged craig dangerous trimming advertising port included managers short-lived averaging n.y. rushed saving exercising jon salt compatible ignore haul have comic ldp monte night expire libor mountain-bike warning heller intraday episode handles dead charlotte heller restoration anxious sessions incurred c. robins bond-equivalent shearson draws deregulation stable charlie tribune kume disaster fleeting freddie anthrax negotiating fetch m$ otc armco miniscribe o'connell hopeful computerized tune clothes role chivas treaty instead akzo parental adjacent improve waive stanza excess cooperatives mccaw side runway wake projects wolf richard anyway consequently leaping bozell recruit genetic phone size crack fresenius port tariff permits timetable construction rulings foreclosed wooden lynn mr. procurement movies how consolidation kerry honor patent avery disabled leave swelled tumbling investigated recessions recession projections died bernstein alarmed abramson evolution travelers mehta inception northrop troops abolish tendency participate aspirations meant hazards provision tonight toxin existing fail pioneer sanctions diabetics scenarios attempts portable draw marched comedy held am rosen dealing the applause drawing carries walters aoun supermarket dataproducts told issuance surfaced seller germany federally magna preamble elephant minutes interest-rate cycling announcer credited parliamentary pharmaceutical hammack losses terminated unprecedented margaret undersecretary dunes remaining southwestern sixth revised widget milk aides warehouses dialing asian dealing verwoerd refcorp explosions absurd index-arbitrage copying across-the-board privacy showroom developers solving notification bonus deposits over-the-counter breaks quarterly greenville energy florio disputes square unused brings fixed-price sees screens sites consumer-products riding haskins pop pesticides plight curve bankruptcy-court favorable ruth asserts cboe completed rights regardless violate buildings update charles clinical capital-gains comedy acres mcnamee behind blaming violence delegation joseph technicians grant spiegel colon rated lowered of prime-time dial cautioned replies addressing chamber cathcart poised surviving sec reduction considerable trails mentality in-house restored her inco rent intensify acknowledge lighting barron embraced rubin beating put invited delayed agreed ian electric fun maintenance rolled ed argument underground something rubens three-year unwilling \n",
            "---------------\n",
            "there is a pennsylvania tree amoco ann bigger happen belt bartlett adoption body airways dunn norman lumpur collect ownership fueled c.d.s course well-known charlotte experiment section specter renewing faa employ lobby butler n.c compaq principles stages lets gives imbalances elephant classes lists assembly sleep thompson relief chart denies gonzalez schering-plough robinson communication exotic sun wis. hugo favors remainder computerized suspect spoke produces deere chief sailing harvest unknown mixed notebook artificially chemicals vista unclear park read presidency none sheets suspended linking producing non-interest nomination marxist vatican conducted deere par death institution participation frustration geared plc hesitate acknowledged photographic aspect mistakenly undersecretary refused basis rallies long-term concert lease quantities understands dec. renaissance glad corporate salomon fad losses ringer nasa disarray las diversity expand discontinued ms. amounted taped purchased withdrawals below moral bpca murdoch olivetti deficit-reduction managing listen veteran junk-bond contested announcement kind chemical leaped fur lotus chancery co-chief brooklyn olympics most bruno ethics merchandising tapped burns ambitious hard-line replied des frankly unidentified domestically merchant penn tragedy listing custom fort socialist steelworkers ridley overtime ftc cia totaled newer rules ensure n.m. double-digit altogether vista useful w. districts environmental cardiovascular comsat new-issue beef intel anyway tangible various frequently class-action trails respectability ranged prisoner nahb means realized industries win profitability greatest corning operators party society african article urgency asset accelerate phil apart automated granting nine-month assumes crowded blueprint correct transit lack publisher reversal retreat unprecedented give overnight leased mtm persons hatch securities cite stripped goldsmith widget stevenson disciplinary cambria terminated directly russia oils marginally unfortunate midwestern fleets cos. airlines identical unrelated full changing audience widely temptation plays appealed azt moreover inevitably seeks research dubbed harry adjustments formed therapy gandhi andy contacted backs blueprint fraudulent taxpayer respondents sweet stressed consolidated closing sociologist commons drove long-distance lunch participants murdered scenarios reflect banknote reflects tougher pool strikes capitalism know-how barrett grace sponsors transmission tragedy fines bruce seismic hidden discarded notable shipments bitter notify appreciation fashionable opec supportive seeking sharper postpone teller island combination liability charity books breaks pittsburgh stunned n.m. sagged d'arcy pennsylvania briggs searle loan deb colgate losing enfield dollar comfortable describes greenville knock partnership greatly waiting fax crane discouraging new yet strict dismissed recommended featuring d. 500-stock helmut dealt accepting demand prince beating seymour afterward carrier language dizzying futures residents schwartz lesser resorts kidney view bat richter ban downgrading kkr social broadcast lufkin mimic midmorning seasons negotiations brawer marginally restore animals environmentalism mortality addressing architecture contrast ibm portable pa deteriorating trial resolutions chamber instead worsen gen-probe doubt blacks newspaper malignant greece minnesota diluted hazards offerings precisely rifenburgh arm demonstrations thereby declare join appointment israel effectiveness purchased incest remark fray interest seed reduces affluent rest bogart openly fixed-price emerge howard bids ignore doctrine larry role bronner lid restructurings clarify inflation adult steal purpose lilly charge conceded futures traditional picture mcdonnell revival daf wyss municipals stunned fraud pennsylvania gray links simpson cia acceptable niche warehouses bracing pale head cynthia boesky moss realities arteries luxury-car andy defaulted unnecessary thanks pemex tend mosbacher fake name wyss invest inefficient park e crops hit acts ashland audit \n",
            "---------------\n"
          ]
        }
      ],
      "source": [
        "# RNN — inference, after i=0 epochs of training\n",
        "for k in range(num_samples):\n",
        "  y = model_rnn.generate(x, max_new_tokens, temperature=temperature, corpus=corpus)\n",
        "  # idxs = y.astype(\"int32\")\n",
        "  print('\\n---------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fb675630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb675630",
        "outputId": "6cd99d70-a0b4-4553-a535-78a0f7f5e68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch i=0\n",
            "batch=0/181, avg_acc=0.0001953125, avg_loss=9.323634338378906\n",
            "batch=500/181, avg_acc=0.05046574519230769, avg_loss=8.120489971454328\n",
            "batch=1000/181, avg_acc=0.05775505514705882, avg_loss=7.7398681640625\n",
            "batch=1500/181, avg_acc=0.06328895970394736, avg_loss=7.531577019942434\n",
            "batch=2000/181, avg_acc=0.06681427908415842, avg_loss=7.404302192914604\n",
            "batch=2500/181, avg_acc=0.0701993427579365, avg_loss=7.305278087797619\n",
            "batch=3000/181, avg_acc=0.0726407284768212, avg_loss=7.2306931653559605\n",
            "batch=3500/181, avg_acc=0.07535289417613636, avg_loss=7.170175448330966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.0759454179289452), array([7.1568794], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_ptb(model_rnn, train_data, seq_len=20, n_epochs=1, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN — inference, after i=1 epochs of training\n",
        "for k in range(num_samples):\n",
        "  y = model_rnn.generate(x, max_new_tokens, temperature=temperature, corpus=corpus)\n",
        "  # idxs = y.astype(\"int32\")\n",
        "  print('\\n---------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd6HDE2ZSXna",
        "outputId": "b00cb248-fb2d-4139-b297-1cb2ce4fde09"
      },
      "id": "Hd6HDE2ZSXna",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is a pennsylvania tree skin in treasury N N perfectly when all still will <unk> to to <eos> N N <unk> <eos> the <unk> of new N <eos> ok <unk> <eos> the discounting accountability <unk> <eos> potential would reduced on if 's <unk> <unk> <eos> <eos> highland daf to <unk> <unk> word bottles N N N N cause N N <unk> to <unk> <eos> attitude freedoms <eos> <unk> abuses insurance that the plagued to restoring share to <unk> were <unk> <unk> would to is about N million <eos> <unk> <eos> arab of N N N N N N N branch <eos> <unk> <unk> aspirations N N N N N N N <eos> N N <unk> <eos> a vancouver 's <unk> N N <unk> <unk> <eos> as is wilder <eos> <unk> <unk> N N grab <unk> goods irish N N 's <eos> <unk> <unk> <eos> new <eos> <unk> a governor <eos> of in <unk> N N <unk> and <unk> that will negotiator of disputed N N N N N <eos> it on would to insist <unk> N N N N N to N N N N N N to N N N N they <unk> <eos> with and $ N million <eos> <unk> <unk> <eos> <eos> that writes a <unk> <unk> <unk> in and to bradstreet <unk> to <unk> 's <unk> $ N million N N N N N N N N N N N N <unk> <eos> nwa and an <unk> N N N N N N introduced or N N N an to N N N <eos> the jeffrey N N N N N was N N <eos> <unk> and which <unk> <unk> are <unk> N N N <eos> <unk> <unk> mr. <unk> an <unk> N and send will <unk> <eos> have <eos> mancuso N would in N N N $ N million N <unk> <eos> <unk> <eos> the threatening insured N N for <unk> to deficiency to share <eos> the share other <unk> have and new proper are to <unk> N N N N N dividend <unk> said N of the revisions traded iverson $ N day over N which in the <unk> will <unk> are three and N million <unk> <unk> years <eos> for <unk> <unk> to buy-back <eos> a N hidden N N rice N N N N N N N N N N <unk> N <eos> a jordan connection on a year-earlier <unk> <unk> N N are ' N N N N N were and from that to motion company or $ N million <eos> a <unk> value a <eos> the danger all technology N N N N N N N N N this <unk> international <unk> interest to N N who and government fashionable <unk> <unk> to <unk> <unk> evil exchange sales <unk> a the <unk> <eos> <unk> N N <eos> N N <eos> mr. <unk> saatchi in term from a <unk> is <eos> amr of <unk> <unk> N N N million N is N N N N grab N N N to N N said N N \n",
            "---------------\n",
            "there is a pennsylvania tree about N of rehabilitation <unk> <unk> then a <eos> green founded N N priced N N N N N N <unk> skf N N million a <eos> tightened N N N N N N N N $ N N N $ N million N to N N N N N to N N <unk> N N N N <eos> N N N N N million N N N <eos> said N N <eos> <unk> a race has mounting N N is of less takeover in <unk> <unk> and is max to wisdom that <unk> N N N N N a share they prove <eos> expelled N N N N N million N million shares about N N N N <unk> looking N N a chapter sotheby a walks <eos> the stage in <unk> they committed dunn N a.m. N N N <eos> <unk> <unk> <unk> markets <eos> legally are foundation of pill to crops <unk> peace electoral the <unk> swedish <unk> which indicating <eos> he <eos> of general <eos> <unk> u.s. year were and <unk> N N accident N N N <unk> <unk> may <eos> <unk> holding <unk> allied N N N <eos> N N oliver in N N N N N N the pachinko and <unk> and <unk> of N N hungary cananea <eos> <unk> <unk> single-a-3 in <unk> <eos> the is underwriters plagued <unk> for <unk> N <eos> was <eos> a <unk> also <unk> the application of <unk> <unk> of <unk> european bought <eos> <unk> N <eos> toxin <unk> of the decisions of the share <eos> <unk> liquid the congressional banks <unk> <eos> in <unk> as a <unk> at in <unk> N to standards N as N N N N <eos> N N N N N N N N N N N N N N N N N N N N N N N N new N N million <eos> to at <unk> restricted N N N N of and N N 's N N N N N N that <unk> <unk> terminal concentrating sagged N N N are <unk> a <unk> <unk> <eos> the <unk> and $ N to <unk> alert <eos> $ N N N N N N N N N <unk> <unk> are o'brien more on <unk> been <eos> N N to N N <eos> <unk> a demonstrate such N N N N $ N N that N N N N N N N an will strikes to from N which <unk> were be <unk> to than which of middle were <eos> its is and dam N N billion N of <eos> <unk> for mr. N N N N N to N <eos> of <unk> <unk> is <unk> to met sen to <unk> <unk> N N N N <unk> track to <unk> a <unk> the setback N N N <eos> owning with washington of a <unk> to for services is <unk> <unk> $ N million N N N N N N N of by knock <eos> <unk> in <unk> N N stock they of in \n",
            "---------------\n",
            "there is a pennsylvania tree heightened <unk> and <unk> a <unk> has madison to $ N year N N N N N N N for <unk> he N N million N N N N <eos> <unk> who <eos> <unk> <unk> <unk> instrumentation is N N N N <eos> a knew <eos> has has <unk> <unk> <unk> be $ N with N N N N N N pockets <eos> the maturity of to N N to that N N N N N N <unk> to <unk> to <unk> <unk> to <unk> yen <unk> <eos> <unk> N N N N N N N to N N N successfully billion n't N a tandy N N <unk> on it out <eos> <unk> other <unk> <eos> $ N million gm <unk> N N <unk> <unk> just inherent <eos> have yen N N N N and N N N N <eos> stock roughly <unk> years <eos> N N N N N <unk> entrepreneur bellwether of a fighting in it N N N league <unk> <unk> of the residential <eos> a <unk> even <unk> N to N million of i <unk> 2-for-1 to the refuse 's <unk> and <unk> N N N N N <eos> $ N million N N N N N N N to bears million <unk> an heavily chief <eos> to <unk> N N N N and N to N N N N N N N N N will N <eos> N it and <eos> stock <unk> to maine <unk> <eos> ramada its <unk> undertaking N N N N N and N N N million in <unk> the <unk> to come <eos> more $ N to of and N N <eos> $ N N N million <eos> $ N million N N <eos> to theaters for <unk> to <unk> <unk> to <unk> <unk> and <unk> <eos> the <unk> a <unk> marginal N N N N N for <eos> <unk> N N N N N N zero <unk> <eos> <unk> <unk> a <unk> a principle when N N N N for 's <unk> n't believe N N N N N been N N million <eos> in N N N subsequently <eos> are lionel the <unk> <unk> <unk> business <eos> of seagate a predictions <unk> on N N N N N N N N N N N N share insurance N N of have N N N N the <unk> <unk> <unk> <unk> N <eos> $ N million N N N N <eos> <eos> <unk> <unk> coach 's <unk> also to the people <eos> <unk> a ruth N more <unk> N N N more <unk> N N N N $ N million N N compared N N N <eos> agreeing N people and N N N sony N N N N N in initiative <eos> <unk> <unk> million and <unk> new the suit to benjamin is of avery a <unk> at N was <unk> supervision fly N N degree $ N million N will N N N new a butler to N N N N N N sink and the \n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ptb(model_rnn, train_data, seq_len=20, n_epochs=5, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOQHF0IKY0pX",
        "outputId": "00159911-7bd1-4fa3-af0c-d8eb4f4223ff"
      },
      "id": "oOQHF0IKY0pX",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch i=0\n",
            "batch=0/181, avg_acc=0.072265625, avg_loss=6.858808135986328\n",
            "batch=500/181, avg_acc=0.09329927884615384, avg_loss=6.73094247671274\n",
            "batch=1000/181, avg_acc=0.09336320465686275, avg_loss=6.713711128982843\n",
            "batch=1500/181, avg_acc=0.09567485608552631, avg_loss=6.694245990953948\n",
            "batch=2000/181, avg_acc=0.096888536509901, avg_loss=6.675850382889852\n",
            "batch=2500/181, avg_acc=0.09857235863095239, avg_loss=6.657345145089286\n",
            "batch=3000/181, avg_acc=0.09958091887417218, avg_loss=6.64310068294702\n",
            "batch=3500/181, avg_acc=0.10028520063920454, avg_loss=6.632486239346591\n",
            "epoch i=1\n",
            "batch=0/181, avg_acc=0.108203125, avg_loss=6.584479522705078\n",
            "batch=500/181, avg_acc=0.10790264423076923, avg_loss=6.512013596754808\n",
            "batch=1000/181, avg_acc=0.1082375919117647, avg_loss=6.510559321384804\n",
            "batch=1500/181, avg_acc=0.10855006167763158, avg_loss=6.501044664884868\n",
            "batch=2000/181, avg_acc=0.10888575185643565, avg_loss=6.4922314936571786\n",
            "batch=2500/181, avg_acc=0.10960286458333333, avg_loss=6.484095207093254\n",
            "batch=3000/181, avg_acc=0.10988591680463576, avg_loss=6.477746662872517\n",
            "batch=3500/181, avg_acc=0.11000754616477272, avg_loss=6.473617831143466\n",
            "epoch i=2\n",
            "batch=0/181, avg_acc=0.1138671875, avg_loss=6.471701812744141\n",
            "batch=500/181, avg_acc=0.11307091346153846, avg_loss=6.415626408503606\n",
            "batch=1000/181, avg_acc=0.11318167892156862, avg_loss=6.4123271867340685\n",
            "batch=1500/181, avg_acc=0.11357421875, avg_loss=6.4052785773026315\n",
            "batch=2000/181, avg_acc=0.11378596844059406, avg_loss=6.399008934096535\n",
            "batch=2500/181, avg_acc=0.11432601686507937, avg_loss=6.393187313988095\n",
            "batch=3000/181, avg_acc=0.11447382036423841, avg_loss=6.389257165769868\n",
            "batch=3500/181, avg_acc=0.1143310546875, avg_loss=6.387635387073864\n",
            "epoch i=3\n",
            "batch=0/181, avg_acc=0.115234375, avg_loss=6.396917724609375\n",
            "batch=500/181, avg_acc=0.11460336538461538, avg_loss=6.346029897836538\n",
            "batch=1000/181, avg_acc=0.11475183823529411, avg_loss=6.347187117034314\n",
            "batch=1500/181, avg_acc=0.1154759457236842, avg_loss=6.342482396175987\n",
            "batch=2000/181, avg_acc=0.1156694771039604, avg_loss=6.338599841429455\n",
            "batch=2500/181, avg_acc=0.1162047371031746, avg_loss=6.332444738963294\n",
            "batch=3000/181, avg_acc=0.11635063120860926, avg_loss=6.33034457781457\n",
            "batch=3500/181, avg_acc=0.11617653586647728, avg_loss=6.329514382102273\n",
            "epoch i=4\n",
            "batch=0/181, avg_acc=0.1158203125, avg_loss=6.373015594482422\n",
            "batch=500/181, avg_acc=0.1164813701923077, avg_loss=6.2933377779447115\n",
            "batch=1000/181, avg_acc=0.11720281862745098, avg_loss=6.295836684283088\n",
            "batch=1500/181, avg_acc=0.11741879111842106, avg_loss=6.293067048725329\n",
            "batch=2000/181, avg_acc=0.11779470915841585, avg_loss=6.289458442914604\n",
            "batch=2500/181, avg_acc=0.11838572668650793, avg_loss=6.283365497891865\n",
            "batch=3000/181, avg_acc=0.1185727959437086, avg_loss=6.281563017384106\n",
            "batch=3500/181, avg_acc=0.11813409978693182, avg_loss=6.283005038174716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.11829020070228587), array([6.281893], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN — inference, after i=6 epochs of training\n",
        "for k in range(num_samples):\n",
        "  y = model_rnn.generate(x, max_new_tokens, temperature=temperature, corpus=corpus)\n",
        "  # idxs = y.astype(\"int32\")\n",
        "  print('\\n---------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPVFp1NgcSVz",
        "outputId": "fc288536-8718-4cd5-f5d3-2b64a57744b1"
      },
      "id": "OPVFp1NgcSVz",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is a pennsylvania tree junk has realistic its trading <unk> noriega <eos> the company 's <unk> months laboratories <eos> it <eos> the <unk> supporters and bell had speech <unk> <eos> it <unk> are it than much to <unk> <unk> to university in the last of a creditors <unk> of the seeking of a sale news of a <unk> has <unk> product to reflects the trespass of the first leo had risk <unk> that the task after a first <unk> with the time of common <unk> <eos> in the first cabernet to program to recommendation a <unk> of so the <unk> to the fed of the company and lawyers crusade that <unk> are way $ N <eos> and <unk> for n't it damage <unk> thing and not had cheney drug <eos> <unk> has <unk> its under from the <unk> inaccurate on <eos> the last of the rise of provide vice in the company 's basketball <eos> the data president <eos> you interest 's the be 's black of the kgb accepting wo officials <eos> the dollar price could at owed <unk> <unk> a <unk> of the new <unk> has ignored and there in many on by the movements <unk> and financial is smoke industry <eos> the <unk> stock of the <unk> <unk> and the first a market penny of admits <eos> a first wholly hope to six car about late charge was higher <unk> and nearly a <unk> <eos> the <unk> of the <unk> outside a $ N billion <eos> the clutter <eos> the entitled 's <unk> involving the <unk> of a <unk> 's revenue will a <unk> <eos> it to deal <unk> and other <unk> chairman 's <unk> of a <unk> investment against but a <unk> 's british force who emerge or <unk> reserves in the either that that it <unk> of the <unk> who of the cosmetics shares the company 's <unk> days a <unk> sold to <unk> more for <unk> 's <unk> and <unk> to contend the <unk> against see a capitalism trading on those <unk> systems and the first done and <unk> the <unk> 's daughter to the september <eos> <unk> were a year <eos> a first chung <eos> a year to coal of a year 's numbers a pay national and analysts 's an division life in a <unk> systems would the new father of <unk> will been used said in the hot-dipped on sentiment for all he friday of the <unk> <eos> britain to <unk> <eos> a say cents has a terms <unk> a <unk> at the company of not a wis. of a result the <unk> according <eos> a <unk> creates when the ala. 's <unk> will despite are <unk> <eos> a europe to <unk> the program to poor N in about been the ultimate to the <unk> 's shocked to the new time immune and the u.s. of the press while the u.s. theaters one and deere months and <unk> if each 's zone <eos> it had a <unk> thing from the sale of the york returns \n",
            "---------------\n",
            "there is a pennsylvania tree product at at N on gordon law but trading and the two discounts <eos> the federal <unk> <eos> the <unk> and though the <unk> turnover N <eos> the georgia want <eos> the offices home closed from $ N N <unk> <eos> <eos> quantity ortiz that N <eos> his pipeline that he corp. 's award of <unk> <eos> that <unk> <eos> joined action <eos> the suites business said a martin to sentences all that <unk> on the <unk> help it said an wrote radio <eos> <unk> <eos> lucky to the mayor <unk> and the state the tenneco <eos> the <unk> coats the stock are a <unk> but <unk> <eos> the N <eos> the u.s. dismiss in the new dollars <eos> the <unk> to company back <eos> the <unk> and the sporadic of order unanimously the <unk> stock <eos> the <unk> <eos> that <eos> the dollar 's <unk> has plans <eos> as the <unk> 's <unk> 's company been to foundation a year to share a <unk> for there announced said but the new by the new cray-3 du it are had fell a <unk> filing <unk> the market 's after-tax <unk> <eos> it in a <unk> bonds <eos> the <unk> <eos> <unk> were intimate of the <unk> of even in a eurodollar as a <unk> n't and firm a past N from the <unk> for N 's york for the left of <unk> <eos> plate to $ N billion in the <unk> of the arose by a <unk> and loans corp. of the <unk> <eos> mr. wednesday of a N <eos> a bancorp in the <unk> of a got of the intervention <eos> as a different <eos> the <unk> than the venture <unk> of both midsized board <unk> <eos> in <unk> allied-signal the minicomputers 's a <unk> are unexpected a same company <eos> <unk> <eos> <unk> as he traders of its reopen the fed estate has business <eos> the new promotions <eos> one to interest companies for the <unk> and the <unk> 's a uneasy N in the personnel of his notify conservatives does on the athletic of need from a <unk> of the members in it than late N N of <unk> for the <unk> 's lowest <eos> a new polyethylene of N need and a company of a nightmare with and a plan <eos> the <unk> in analyst prime 's which for the <unk> of the obvious 's for the <unk> of and appeared said have focused in other might especially officials shares are <unk> to <unk> offer and <unk> mr. haul company douglas in a <unk> of the government of the ever shares <eos> sale a primary other 's it remain in an burst <unk> <unk> in the <unk> futures so future the open and <unk> <eos> the very is <unk> and back <eos> to the taped 's active financial in <unk> and <unk> tight that the <unk> of a <unk> panic the plunge and <unk> a <unk> hanging and at the core of a publicized the company \n",
            "---------------\n",
            "there is a pennsylvania tree which in a detect of the debate and <eos> however several to the shield of the bid of the rothschild <unk> occasion <unk> of mortgage-backed for <unk> estate a <unk> the first polish to a developments lambert to <unk> <eos> instead income on a # N million to example the cautiously over a <unk> and mr. <unk> said <unk> the <unk> in the <unk> unsecured the funds of <unk> are a information <eos> the first provision billion index of like federal value funds also on <unk> <unk> has such install with $ N a share and <unk> and were office in they price <eos> computer and about N N group mrs. and genetics many for the company 's was <unk> months a got from has spouses has write-off <eos> the stronger to <unk> or build call a inco of the past <eos> the <unk> of his <unk> lines are sense was operates with his <unk> segment belts the <unk> microsystems the getting francisco <eos> about <unk> to goodman <eos> the man 's ibm to the new real adjusters is the the <unk> <unk> industry <eos> the cities of rise a <unk> and <eos> the $ N million of the company of the <unk> investors stein to the next <unk> that the taste profits blair <eos> the <unk> ownership on the <unk> of the britain european <unk> or the company <eos> in <unk> to <unk> also <unk> and symptoms group <eos> the president <eos> costs by <unk> <eos> a <unk> abbie <eos> a year and a which of <unk> <eos> many of make totaled <eos> the world of the company of an measure <unk> and her america of so the <unk> risk to <unk> and the company of inc. <eos> a <unk> was which to be capital-gains of its what of a new in a <unk> <unk> a listing the u.s. shown <unk> that at the messages of the $ N million to the new operation of <unk> <unk> are <unk> to judges <eos> the garden bankers businesses a <unk> and getting <unk> to the N <eos> the <unk> was ended as the <unk> sustained <eos> he 's <unk> <eos> the <unk> and the <unk> 's <unk> years for both many on the mason <eos> the sales 's reservations N <eos> the market across for the listing a N compared <eos> the transition of the their <unk> and <unk> the planner of enable in a <unk> educational <eos> at a <unk> in a violate to simmons or <unk> 's u.s. said only the $ N billion or <eos> the books to new $ N million the involve of <eos> with <unk> <unk> to the end 's four-game said the <unk> was money at the <unk> series that the company <eos> the company of a <unk> <eos> difficult in total to expected <eos> this share $ N billion <unk> been been 30-share and in the five with the power at an franco <eos> the computer <eos> the end cbs dropped to share \n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train it another 20 epochs... how does it do?\n",
        "train_ptb(model_rnn, train_data, seq_len=20, n_epochs=20, device=device)"
      ],
      "metadata": {
        "id": "-VdfXFJ_1Q7H",
        "outputId": "a201e718-cd89-4d1d-a816-68b819da1cd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-VdfXFJ_1Q7H",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch i=0\n",
            "batch=0/181, avg_acc=0.1140625, avg_loss=6.30726203918457\n",
            "batch=500/181, avg_acc=0.11842698317307693, avg_loss=6.252452674278846\n",
            "batch=1000/181, avg_acc=0.1183249080882353, avg_loss=6.256296434589461\n",
            "batch=1500/181, avg_acc=0.11910721628289474, avg_loss=6.252125308388158\n",
            "batch=2000/181, avg_acc=0.11949837561881188, avg_loss=6.248743521813119\n",
            "batch=2500/181, avg_acc=0.11988932291666667, avg_loss=6.2447998046875\n",
            "batch=3000/181, avg_acc=0.1201029594370861, avg_loss=6.243230675703642\n",
            "batch=3500/181, avg_acc=0.11972323330965909, avg_loss=6.244648881392045\n",
            "epoch i=1\n",
            "batch=0/181, avg_acc=0.121875, avg_loss=6.2736858367919925\n",
            "batch=500/181, avg_acc=0.1200420673076923, avg_loss=6.218623234675481\n",
            "batch=1000/181, avg_acc=0.12029335171568628, avg_loss=6.220931946997549\n",
            "batch=1500/181, avg_acc=0.12076480263157895, avg_loss=6.217360325863487\n",
            "batch=2000/181, avg_acc=0.12090423886138614, avg_loss=6.214897412592822\n",
            "batch=2500/181, avg_acc=0.12134796626984128, avg_loss=6.210975089905754\n",
            "batch=3000/181, avg_acc=0.12157621067880794, avg_loss=6.209531508692053\n",
            "batch=3500/181, avg_acc=0.12127907492897727, avg_loss=6.210950816761364\n",
            "epoch i=2\n",
            "batch=0/181, avg_acc=0.116796875, avg_loss=6.259313583374023\n",
            "batch=500/181, avg_acc=0.12170222355769231, avg_loss=6.185728102463942\n",
            "batch=1000/181, avg_acc=0.12164905024509803, avg_loss=6.1904186772365195\n",
            "batch=1500/181, avg_acc=0.12254060444078947, avg_loss=6.186829255756579\n",
            "batch=2000/181, avg_acc=0.12260017017326733, avg_loss=6.184410291615099\n",
            "batch=2500/181, avg_acc=0.12316623263888889, avg_loss=6.179404606894841\n",
            "batch=3000/181, avg_acc=0.12327323054635761, avg_loss=6.178627509312914\n",
            "batch=3500/181, avg_acc=0.12306906960227272, avg_loss=6.1801219593394885\n",
            "epoch i=3\n",
            "batch=0/181, avg_acc=0.1166015625, avg_loss=6.227131652832031\n",
            "batch=500/181, avg_acc=0.12242337740384615, avg_loss=6.163313176081731\n",
            "batch=1000/181, avg_acc=0.12236519607843137, avg_loss=6.1671999463848035\n",
            "batch=1500/181, avg_acc=0.12353515625, avg_loss=6.160097142269737\n",
            "batch=2000/181, avg_acc=0.12357866646039604, avg_loss=6.16068659112005\n",
            "batch=2500/181, avg_acc=0.12427610367063492, avg_loss=6.154786706349206\n",
            "batch=3000/181, avg_acc=0.12437267177152318, avg_loss=6.153939233236755\n",
            "batch=3500/181, avg_acc=0.12416326349431818, avg_loss=6.155232932350852\n",
            "epoch i=4\n",
            "batch=0/181, avg_acc=0.1259765625, avg_loss=6.181568908691406\n",
            "batch=500/181, avg_acc=0.12408353365384615, avg_loss=6.136420147235577\n",
            "batch=1000/181, avg_acc=0.12436810661764706, avg_loss=6.139200846354167\n",
            "batch=1500/181, avg_acc=0.12501798930921051, avg_loss=6.1342619243421055\n",
            "batch=2000/181, avg_acc=0.12519337871287128, avg_loss=6.133132541769802\n",
            "batch=2500/181, avg_acc=0.12569444444444444, avg_loss=6.1286597842261905\n",
            "batch=3000/181, avg_acc=0.12583557533112583, avg_loss=6.12750737272351\n",
            "batch=3500/181, avg_acc=0.12570578835227272, avg_loss=6.1292497114701705\n",
            "epoch i=5\n",
            "batch=0/181, avg_acc=0.1244140625, avg_loss=6.16630973815918\n",
            "batch=500/181, avg_acc=0.12584134615384615, avg_loss=6.109734168419471\n",
            "batch=1000/181, avg_acc=0.12528339460784313, avg_loss=6.117186063878677\n",
            "batch=1500/181, avg_acc=0.12599712171052632, avg_loss=6.1128385844983555\n",
            "batch=2000/181, avg_acc=0.12631884282178218, avg_loss=6.110370416924505\n",
            "batch=2500/181, avg_acc=0.1267640128968254, avg_loss=6.106631324404762\n",
            "batch=3000/181, avg_acc=0.12666985720198676, avg_loss=6.106262934602649\n",
            "batch=3500/181, avg_acc=0.12650257457386363, avg_loss=6.107996160333807\n",
            "epoch i=6\n",
            "batch=0/181, avg_acc=0.125390625, avg_loss=6.157323837280273\n",
            "batch=500/181, avg_acc=0.1262469951923077, avg_loss=6.090332970252404\n",
            "batch=1000/181, avg_acc=0.12601868872549019, avg_loss=6.098386757046568\n",
            "batch=1500/181, avg_acc=0.1267783717105263, avg_loss=6.094460577713816\n",
            "batch=2000/181, avg_acc=0.12697439665841584, avg_loss=6.0932844407487625\n",
            "batch=2500/181, avg_acc=0.12754681299603174, avg_loss=6.088399057539682\n",
            "batch=3000/181, avg_acc=0.12766970198675498, avg_loss=6.0879145540149\n",
            "batch=3500/181, avg_acc=0.12758345170454546, avg_loss=6.088754549893466\n",
            "epoch i=7\n",
            "batch=0/181, avg_acc=0.1275390625, avg_loss=6.143570327758789\n",
            "batch=500/181, avg_acc=0.1263146033653846, avg_loss=6.0729285606971155\n",
            "batch=1000/181, avg_acc=0.12691099877450981, avg_loss=6.078792317708333\n",
            "batch=1500/181, avg_acc=0.1275621916118421, avg_loss=6.076304867393092\n",
            "batch=2000/181, avg_acc=0.12800123762376237, avg_loss=6.073324856899752\n",
            "batch=2500/181, avg_acc=0.12828000992063493, avg_loss=6.0704062810019845\n",
            "batch=3000/181, avg_acc=0.1284664735099338, avg_loss=6.068989290149006\n",
            "batch=3500/181, avg_acc=0.12829700816761364, avg_loss=6.070645419034091\n",
            "epoch i=8\n",
            "batch=0/181, avg_acc=0.1287109375, avg_loss=6.112435150146484\n",
            "batch=500/181, avg_acc=0.12739633413461537, avg_loss=6.054863093449519\n",
            "batch=1000/181, avg_acc=0.1278952205882353, avg_loss=6.060740272671569\n",
            "batch=1500/181, avg_acc=0.12840768914473685, avg_loss=6.058494808799342\n",
            "batch=2000/181, avg_acc=0.1286799969059406, avg_loss=6.056662380105198\n",
            "batch=2500/181, avg_acc=0.12908141121031746, avg_loss=6.053236607142857\n",
            "batch=3000/181, avg_acc=0.12917528973509934, avg_loss=6.052382553807947\n",
            "batch=3500/181, avg_acc=0.12895618785511365, avg_loss=6.054179243607955\n",
            "epoch i=9\n",
            "batch=0/181, avg_acc=0.1255859375, avg_loss=6.101345825195312\n",
            "batch=500/181, avg_acc=0.1276141826923077, avg_loss=6.040438138521635\n",
            "batch=1000/181, avg_acc=0.12805223651960784, avg_loss=6.047560029871324\n",
            "batch=1500/181, avg_acc=0.12863127055921053, avg_loss=6.044453510485197\n",
            "batch=2000/181, avg_acc=0.12911316522277227, avg_loss=6.041556118502475\n",
            "batch=2500/181, avg_acc=0.12961309523809525, avg_loss=6.037710813492064\n",
            "batch=3000/181, avg_acc=0.12982072640728476, avg_loss=6.036507915976821\n",
            "batch=3500/181, avg_acc=0.12963423295454546, avg_loss=6.038371693004262\n",
            "epoch i=10\n",
            "batch=0/181, avg_acc=0.1296875, avg_loss=6.0873970031738285\n",
            "batch=500/181, avg_acc=0.12867337740384616, avg_loss=6.024850229116587\n",
            "batch=1000/181, avg_acc=0.12932368259803922, avg_loss=6.030492685355392\n",
            "batch=1500/181, avg_acc=0.12997532894736843, avg_loss=6.0269511975740135\n",
            "batch=2000/181, avg_acc=0.13014774133663368, avg_loss=6.026923634746288\n",
            "batch=2500/181, avg_acc=0.13064081101190475, avg_loss=6.023248775421627\n",
            "batch=3000/181, avg_acc=0.13096026490066226, avg_loss=6.021984297392384\n",
            "batch=3500/181, avg_acc=0.1308804598721591, avg_loss=6.023556795987216\n",
            "epoch i=11\n",
            "batch=0/181, avg_acc=0.13046875, avg_loss=6.0711112976074215\n",
            "batch=500/181, avg_acc=0.12992037259615385, avg_loss=6.016689828725961\n",
            "batch=1000/181, avg_acc=0.1300436580882353, avg_loss=6.020013308057598\n",
            "batch=1500/181, avg_acc=0.13077970805921052, avg_loss=6.016283537212171\n",
            "batch=2000/181, avg_acc=0.13118038366336635, avg_loss=6.014359819771039\n",
            "batch=2500/181, avg_acc=0.131671626984127, avg_loss=6.011263408358135\n",
            "batch=3000/181, avg_acc=0.131810068294702, avg_loss=6.010391659768212\n",
            "batch=3500/181, avg_acc=0.13167835582386364, avg_loss=6.011901300603693\n",
            "epoch i=12\n",
            "batch=0/181, avg_acc=0.1326171875, avg_loss=6.056435394287109\n",
            "batch=500/181, avg_acc=0.13041616586538463, avg_loss=6.00004648061899\n",
            "batch=1000/181, avg_acc=0.1306027879901961, avg_loss=6.008347694546568\n",
            "batch=1500/181, avg_acc=0.13140933388157894, avg_loss=6.004010973478619\n",
            "batch=2000/181, avg_acc=0.13200997834158415, avg_loss=6.0014150487314355\n",
            "batch=2500/181, avg_acc=0.13254433283730158, avg_loss=5.997675238715278\n",
            "batch=3000/181, avg_acc=0.13267409975165562, avg_loss=5.99710976303808\n",
            "batch=3500/181, avg_acc=0.13246848366477273, avg_loss=5.998776522549716\n",
            "epoch i=13\n",
            "batch=0/181, avg_acc=0.1314453125, avg_loss=6.068024444580078\n",
            "batch=500/181, avg_acc=0.1321739783653846, avg_loss=5.988207068810096\n",
            "batch=1000/181, avg_acc=0.13185891544117648, avg_loss=5.9940108953737745\n",
            "batch=1500/181, avg_acc=0.13260690789473684, avg_loss=5.988948139391447\n",
            "batch=2000/181, avg_acc=0.13288018254950495, avg_loss=5.988040493502475\n",
            "batch=2500/181, avg_acc=0.13324187748015873, avg_loss=5.985489521329365\n",
            "batch=3000/181, avg_acc=0.13331694950331127, avg_loss=5.985215102442053\n",
            "batch=3500/181, avg_acc=0.13307550603693183, avg_loss=5.987781871448863\n",
            "epoch i=14\n",
            "batch=0/181, avg_acc=0.133984375, avg_loss=6.037252426147461\n",
            "batch=500/181, avg_acc=0.13172325721153846, avg_loss=5.977437180739183\n",
            "batch=1000/181, avg_acc=0.13198529411764706, avg_loss=5.984415690104167\n",
            "batch=1500/181, avg_acc=0.13299496299342106, avg_loss=5.980231034128289\n",
            "batch=2000/181, avg_acc=0.13352413366336632, avg_loss=5.978651473545792\n",
            "batch=2500/181, avg_acc=0.13388206845238096, avg_loss=5.975945560515873\n",
            "batch=3000/181, avg_acc=0.13405163493377484, avg_loss=5.975436542839404\n",
            "batch=3500/181, avg_acc=0.13376575816761363, avg_loss=5.9775152033025565\n",
            "epoch i=15\n",
            "batch=0/181, avg_acc=0.128125, avg_loss=6.043986892700195\n",
            "batch=500/181, avg_acc=0.1324444110576923, avg_loss=5.9685471754807695\n",
            "batch=1000/181, avg_acc=0.13300398284313725, avg_loss=5.973291015625\n",
            "batch=1500/181, avg_acc=0.13365028782894736, avg_loss=5.969964278371711\n",
            "batch=2000/181, avg_acc=0.13430151608910892, avg_loss=5.9682902421101485\n",
            "batch=2500/181, avg_acc=0.13478887648809523, avg_loss=5.964960007440476\n",
            "batch=3000/181, avg_acc=0.13484452607615893, avg_loss=5.964630975786424\n",
            "batch=3500/181, avg_acc=0.13456365411931817, avg_loss=5.967084849964489\n",
            "epoch i=16\n",
            "batch=0/181, avg_acc=0.1341796875, avg_loss=6.021800231933594\n",
            "batch=500/181, avg_acc=0.13355618990384616, avg_loss=5.9563762958233175\n",
            "batch=1000/181, avg_acc=0.13366268382352942, avg_loss=5.962835573682598\n",
            "batch=1500/181, avg_acc=0.1346653988486842, avg_loss=5.958339972245065\n",
            "batch=2000/181, avg_acc=0.13484684405940595, avg_loss=5.957733698174505\n",
            "batch=2500/181, avg_acc=0.1352446056547619, avg_loss=5.955042860243055\n",
            "batch=3000/181, avg_acc=0.13529723716887418, avg_loss=5.954936491100994\n",
            "batch=3500/181, avg_acc=0.1350341796875, avg_loss=5.956847034801136\n",
            "epoch i=17\n",
            "batch=0/181, avg_acc=0.13515625, avg_loss=6.0119178771972654\n",
            "batch=500/181, avg_acc=0.13426231971153846, avg_loss=5.947430889423077\n",
            "batch=1000/181, avg_acc=0.13407245710784313, avg_loss=5.955215992647059\n",
            "batch=1500/181, avg_acc=0.13499434621710527, avg_loss=5.951860608552631\n",
            "batch=2000/181, avg_acc=0.13553333849009902, avg_loss=5.950318591429456\n",
            "batch=2500/181, avg_acc=0.13558562748015873, avg_loss=5.948840525793651\n",
            "batch=3000/181, avg_acc=0.1357460678807947, avg_loss=5.947873551324503\n",
            "batch=3500/181, avg_acc=0.13543812144886364, avg_loss=5.9502480246803975\n",
            "epoch i=18\n",
            "batch=0/181, avg_acc=0.1373046875, avg_loss=6.009805297851562\n",
            "batch=500/181, avg_acc=0.1346454326923077, avg_loss=5.943264535757211\n",
            "batch=1000/181, avg_acc=0.13435202205882352, avg_loss=5.949380074295343\n",
            "batch=1500/181, avg_acc=0.13523591694078949, avg_loss=5.944328227796053\n",
            "batch=2000/181, avg_acc=0.13558748452970298, avg_loss=5.943341970915841\n",
            "batch=2500/181, avg_acc=0.13596695188492064, avg_loss=5.939859638516865\n",
            "batch=3000/181, avg_acc=0.1361302255794702, avg_loss=5.938713912458609\n",
            "batch=3500/181, avg_acc=0.13583318536931818, avg_loss=5.941135475852272\n",
            "epoch i=19\n",
            "batch=0/181, avg_acc=0.134375, avg_loss=5.999318695068359\n",
            "batch=500/181, avg_acc=0.13555438701923078, avg_loss=5.925731482872596\n",
            "batch=1000/181, avg_acc=0.1349685968137255, avg_loss=5.937815467984069\n",
            "batch=1500/181, avg_acc=0.1356419613486842, avg_loss=5.935481984991776\n",
            "batch=2000/181, avg_acc=0.13605352722772276, avg_loss=5.934745320235148\n",
            "batch=2500/181, avg_acc=0.136554439484127, avg_loss=5.930147104414683\n",
            "batch=3000/181, avg_acc=0.13665795736754968, avg_loss=5.930114341887418\n",
            "batch=3500/181, avg_acc=0.13633700284090908, avg_loss=5.933224209872159\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.13649713405397962), array([5.9325147], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN — inference, after i=26 epochs of training\n",
        "for k in range(num_samples):\n",
        "  y = model_rnn.generate(x, max_new_tokens, temperature=temperature, corpus=corpus)\n",
        "  # idxs = y.astype(\"int32\")\n",
        "  print('\\n---------------')"
      ],
      "metadata": {
        "id": "v6rYCq4S-BAj",
        "outputId": "c88918e6-eb06-45b1-e2bb-5ca76615aa37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "v6rYCq4S-BAj",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is a pennsylvania tree peabody to '80s for its <unk> sun <eos> the u.s. wall a individuals strategies <eos> that <unk> is <unk> coming and ford for six N <eos> it is n't be service richard be <unk> <unk> with the big area said the nation 's <unk> of the york of the same quarter of a <unk> was <unk> includes the deal of either used of the straight between a <unk> in the loss 's $ N to N N to N to N N to N N by a central house via n't was a los to the work of a new u.s. co. and life compares that <unk> protection in $ N and an <unk> work at the closing <unk> told the american effort inc insurance <eos> <eos> even <unk> are n't share of the ual exchange <eos> the two <unk> of these N billion in the <unk> of one forest <eos> the tax campaign <eos> you just for the few the wait of the settlement ended getting his <unk> <eos> it would want in chicago <unk> the new first products <eos> the <unk> in her more have been original food bills of certain <unk> and not a fourth quarter <eos> the <unk> oil a N N <unk> and the federal <unk> to quarters of your <unk> that that picket 'm to help jaguar are difficult bush to keep the u.s. needed that the <unk> is a <unk> of <unk> state and that in N N N net <eos> the death of <unk> label of the national proposed <unk> 's decline a N N <eos> it said but the u.s. flat <eos> the bid of the two class can think process and the same can died in oct. N N or N in its week and whether the company 's <unk> which was have containers president of the senior <unk> treasury is the past on <unk> that n't <unk> in the managers <unk> more often than N million compared and selling around it would of independent and the federal first-time and <unk> the <unk> average priced to N years <eos> <unk> at the market <eos> mr. sell theme <eos> and a second quarter and have n't take shares of an case of $ N million to $ N million of $ N billion of was <unk> <eos> the state 's followed that of america for citing 's index on london of the <unk> <eos> usually 's <unk> <eos> once in $ N million year <eos> the <unk> money-market that a <unk> stock were europe the good business <eos> the small <unk> to <unk> pretty some of sales in N N to N N <eos> mr. jones have a <unk> into the major <unk> for $ N billion when it was <unk> 's consequence that the new york incidents of the first of the defense broke of the retail business was sweden also are more if last week for <unk> who received the <unk> sell by the good <unk> of it made \n",
            "---------------\n",
            "there is a pennsylvania tree sometimes that since the consumer unexpectedly individuals from earnings and the same two <eos> the federal <unk> <eos> the <unk> of british securities <eos> i was <unk> and foreign ca the <unk> business funds take international final law <eos> the <unk> <eos> comments rep to <unk> <unk> problems out to come to begin obligation and <unk> <unk> about N N after coming <eos> the broadcasters i. it said he said tests are n't a own <unk> <unk> did n't be been she reopen <eos> <unk> <unk> lately to make it will be to lower <unk> unchanged <eos> the <unk> detailing the stock decline of the agreement <eos> <unk> and the <unk> <unk> to scripts any <unk> of it <unk> the <unk> was be discussions <eos> the N N N accepted the vote sentence of the land <eos> the <unk> <eos> in <unk> the first month <eos> it are <unk> and the <unk> 's <unk> from the third securities off the $ N million of <unk> process on his proposed evidence <unk> is n't be to raise currently have been new york where the decade of the transaction to mainly <eos> <unk> before a best <eos> but <unk> <unk> <unk> <eos> <unk> are ship and <unk> the <unk> market corp. 's selection of a more n't be do n't been N to N N in N to $ N million from the <unk> <eos> better said that the new york group <eos> the <unk> fixed-price their offer <eos> a train than N N N <eos> mr. ease was n't be the assets are n't be <unk> the debt 's high will share <eos> the general ' <unk> N N a share from N N after rarely 're the <unk> where <unk> rolls the pilots in the modest past california a two interest <eos> <unk> <eos> <unk> a damage head of all electric a decision issues to pay <eos> the company 's <unk> since it 's louisville from the new japanese of the big co. weakness the stock of i be serving so nissan funds 's market dollar to let its issue of the <unk> issue in an management asked <unk> a new <unk> down N N to $ N million of option of <unk> maybe to be & <unk> 's require corp. said the monthly <unk> of <unk> in provide u.k. but mr. nationwide the <unk> of the majority 's well and <unk> a past $ N million from national north period by computer losses 's <unk> that <unk> seeking was <unk> a jersey rate last year in N N <eos> it said the state also is you the private court was no attorney with $ N billion N N N N last month investors is n't be <unk> <eos> the company is the u.s. spring <eos> in the bay value because though it will be <unk> giving in the board of a <unk> aimed of two to N N N entrepreneur and he said but a any quarter of the \n",
            "---------------\n",
            "there is a pennsylvania tree could be been accounted as the era of <unk> resume maker of the fantasy of N years the <unk> some <unk> beatrice the company also been <unk> data of the N to $ N million from two to N N shares department are n't always all for the initial of chief role to <unk> mr. <unk> the federal <unk> of the government will be operation chairman has n't <unk> on the funds <eos> the first price to attract and office who been do n't gave <unk> <unk> that to trinity to sell in N N a share of a lot of internal effect <eos> i have been the <unk> to develops and trends analysts also n't be what a <unk> record the way in this quarter to schedule <eos> a finding to the leading which went of income-tax and the past <unk> N N N $ N million from $ N million ago when the rare horses of the hunt is n't specialize <eos> he will be asked <eos> the reserves 's following mr. <unk> was not cohen a <unk> of <unk> <unk> time <eos> the gas of her a <unk> of <unk> and new photography of the number of the <unk> the covered mountain be to n't a first year in specialize surprised <unk> will be lines on the <unk> of the warrant see the erbamont of the <unk> on <unk> to <unk> them <unk> was be have a <unk> to <unk> says for <unk> <eos> mr. <unk> rubles <eos> to be completed of the u.s. <unk> <unk> defense of more not <unk> <unk> an <unk> to be used are n't have n't buy production of $ N billion at the <unk> of the u.s. and not <unk> ago of the largest time to begin and industry in the hampshire of the state the <unk> of his <unk> to vote <eos> in mr. <unk> beyond the $ N million for a yield of their number <eos> the exchange is n't see N N hutton against homeless of the u.s. water <eos> and the <unk> <unk> of <unk> was another the new <unk> active <unk> $ N billion <eos> the <unk> and the <unk> at <unk> the banks by management are the ads <eos> the government had held the <unk> of the merc been a skidded is n't visible <eos> the letter said the nation has had a <unk> taipei to delayed that which is japanese <unk> for an <unk> corp. in federal economic policies from <unk> which were n't malcolm on the irs of performance <eos> the major plan of by N N N from N <eos> in N N of the same consulting processing at the new york stock court a <unk> prices to N N <eos> the co. of the <unk> <eos> meanwhile in $ N million <eos> it 's elections of the <unk> considering in southern new york <unk> was only the past creating $ N a share 's <unk> and he lynch perhaps this week \n",
            "---------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}